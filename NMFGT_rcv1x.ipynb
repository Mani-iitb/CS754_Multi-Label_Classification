{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix, hstack, vstack, find as sparse_find, issparse\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just to suppress some warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_EVAL = 5 # We are only testing upto precision@5 same as in paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader for BibTex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"Handles loading multilabel data and train/test splits.\"\"\"\n",
    "    def load_multilabel_data(self, filepath):\n",
    "        \"\"\"\n",
    "        Loads data from a LIBSVM multilabel format file.\n",
    "        Args:\n",
    "            filepath (str): Path to the data file.\n",
    "        Returns:\n",
    "            tuple: (X, Y) where X is the feature matrix (csr_matrix n_samples x n_features)\n",
    "                and Y is the label matrix (csr_matrix n_samples x n_labels), or (None, None) if error.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Error: Data file not found at {filepath}\")\n",
    "            return None, None\n",
    "\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                first_line = f.readline().split()\n",
    "                if len(first_line) < 3:\n",
    "                    raise ValueError(\"Invalid header format in data file.\")\n",
    "                n_samples = int(first_line[0])\n",
    "                n_features = int(first_line[1])\n",
    "                n_labels = int(first_line[2])\n",
    "\n",
    "                if n_samples <= 0 or n_features <= 0 or n_labels <= 0:\n",
    "                    raise ValueError(\"Invalid dimensions in header.\")\n",
    "\n",
    "                X_lil = lil_matrix((n_samples, n_features), dtype=np.float64)\n",
    "                Y_lil = lil_matrix((n_samples, n_labels), dtype=np.int8)\n",
    "\n",
    "                for i, line in enumerate(f):\n",
    "                    if i >= n_samples:\n",
    "                        print(f\"Warning: More lines than expected ({n_samples}) in data file. Stopping.\")\n",
    "                        break\n",
    "\n",
    "                    parts = line.strip().split(' ', 1)\n",
    "                    labels_str = parts[0]\n",
    "                    features_str = parts[1] if len(parts) > 1 else ''\n",
    "\n",
    "                    if labels_str:\n",
    "                        try:\n",
    "                            label_indices = [int(l) for l in labels_str.split(',')]\n",
    "                            for label_idx in label_indices:\n",
    "                                if 0 <= label_idx < n_labels:\n",
    "                                    Y_lil[i, label_idx] = 1\n",
    "                                else:\n",
    "                                    print(f\"Warning: Label index {label_idx} out of bounds [0, {n_labels-1}) in line {i+2}. Skipping.\")\n",
    "                        except ValueError:\n",
    "                            print(f\"Warning: Skipping incorrect label string '{labels_str}' in line {i+2}\")\n",
    "\n",
    "                    if features_str:\n",
    "                        for feature_pair in features_str.split(' '):\n",
    "                            try:\n",
    "                                idx_str, val_str = feature_pair.split(':')\n",
    "                                feature_idx = int(idx_str)\n",
    "                                feature_val = float(val_str)\n",
    "                                if 0 <= feature_idx < n_features:\n",
    "                                    X_lil[i, feature_idx] = feature_val\n",
    "                                else:\n",
    "                                    print(f\"Warning: Feature index {feature_idx} out of bounds [0, {n_features-1}) in line {i+2}. Skipping.\")\n",
    "                            except ValueError:\n",
    "                                print(f\"Warning: Skipping incorrect feature pair '{feature_pair}' in line {i+2}\")\n",
    "                                continue\n",
    "\n",
    "            X_csr = X_lil.tocsr()\n",
    "            Y_csr = Y_lil.tocsr()\n",
    "            print(f\"Loaded data: X shape {X_csr.shape}, Y shape {Y_csr.shape}\")\n",
    "            print(f\"X sparsity: {X_csr.nnz / (X_csr.shape[0] * X_csr.shape[1]):.4f}\")\n",
    "            print(f\"Y sparsity: {Y_csr.nnz / (Y_csr.shape[0] * Y_csr.shape[1]):.4f}\")\n",
    "            return X_csr, Y_csr\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data from {filepath}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def load_split_indices(self, filepath):\n",
    "        \"\"\"\n",
    "        Loads 1-based train and test split indices from a file and converts to 0-based.\n",
    "        Args:\n",
    "            filepath (str): Path to the split file.\n",
    "        Returns:\n",
    "            np.ndarray: Array of 0-based indices or None if any error is founded.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Error: Split file not found at {filepath}\")\n",
    "            return None\n",
    "\n",
    "        indices = []\n",
    "        try:\n",
    "            with open(filepath, 'r') as f:\n",
    "                for line_num, line in enumerate(f):\n",
    "                    try:\n",
    "                        indices.extend([int(x) - 1 for x in line.strip().split()])\n",
    "                    except ValueError:\n",
    "                        print(f\"Warning: Skipping non-integer value in split file {filepath}, line {line_num+1}\")\n",
    "            return np.array(indices)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading split indices from {filepath}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_train_test_split(self, data_filepath, train_split_filepath, test_split_filepath):\n",
    "        \"\"\"Loads data and splits it into train/test sets.\"\"\"\n",
    "        print(f\"\\nLoading full dataset from {data_filepath}...\")\n",
    "        X, Y = self.load_multilabel_data(data_filepath)\n",
    "        if X is None or Y is None:\n",
    "            return None, None, None, None\n",
    "\n",
    "        print(f\"Loading train split from {train_split_filepath}...\")\n",
    "        train_indices = self.load_split_indices(train_split_filepath)\n",
    "        if train_indices is None:\n",
    "            return None, None, None, None\n",
    "\n",
    "        print(f\"Loading test split from {test_split_filepath}...\")\n",
    "        test_indices = self.load_split_indices(test_split_filepath)\n",
    "        if test_indices is None:\n",
    "            return None, None, None, None\n",
    "\n",
    "        n_samples = X.shape[0]\n",
    "        if np.any(train_indices < 0) or np.any(train_indices >= n_samples):\n",
    "            print(\"Error: Invalid train indices found.\")\n",
    "            return None, None, None, None\n",
    "        if np.any(test_indices < 0) or np.any(test_indices >= n_samples):\n",
    "            print(\"Error: Invalid test indices found.\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        print(\"\\nSplitting data...\")\n",
    "        X_train, Y_train = X[train_indices], Y[train_indices]\n",
    "        X_test, Y_test = X[test_indices], Y[test_indices]\n",
    "        print(f\"Train shapes: X={X_train.shape}, Y={Y_train.shape}\")\n",
    "        print(f\"Test shapes:  X={X_test.shape}, Y={Y_test.shape}\")\n",
    "\n",
    "        return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConstantPredictor used when the number of classes in a group is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantPredictor:\n",
    "    \"\"\"A simple predictor for cases where all labels in a group are constant.\"\"\"\n",
    "    def __init__(self, value):\n",
    "        if value not in [0, 1]:\n",
    "            raise ValueError(\"Constant value must be 0 or 1\")\n",
    "        self.value = int(value)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.full(X.shape[0], self.value, dtype=np.int8)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        proba = np.zeros((n_samples, 2), dtype=float)\n",
    "        proba[:, self.value] = 1.0\n",
    "        return proba\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMFGT class, which will train the NMFGT model by creating the GT matrix and training many intermediate classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMFGTModel:\n",
    "    \"\"\"\n",
    "    Implements the Multilabel Classification using NMF-based Group Testing.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_groups, k_target_sparsity=K_EVAL, column_sparsity_range=None,\n",
    "                nmf_options=None, classifier_options=None, random_state=42):\n",
    "        \"\"\"\n",
    "        Constructor method to initialize the NMFGTModel.\n",
    "        Args:\n",
    "            n_groups (int): Number of groups (m), the target dimension for reduction\n",
    "            k_target_sparsity (int): Target label sparsity for evaluation and c selection\n",
    "            column_sparsity_range (list or range): Range of column sparsity values (c) to test\n",
    "            nmf_options (dict, optional): Options for scikit-learn's NMF\n",
    "            classifier_options (dict, optional): Options for scikit-learn's LogisticRegression\n",
    "            random_state (int): Random seed for reproducing results\n",
    "        \"\"\"\n",
    "        self.n_groups = n_groups\n",
    "        self.k_target_sparsity = k_target_sparsity\n",
    "        self.column_sparsity_range = column_sparsity_range if column_sparsity_range is not None else list(range(10, 71, 10))\n",
    "        self.random_state = random_state\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        self.nmf_options = {\n",
    "            'init': 'nndsvda', 'max_iter': 200, 'tol': 1e-4,\n",
    "            'solver': 'cd', 'beta_loss': 'frobenius', 'random_state': random_state,\n",
    "            'n_components': self.n_groups\n",
    "        }\n",
    "\n",
    "        if nmf_options:\n",
    "            self.nmf_options.update(nmf_options)\n",
    "            self.nmf_options['n_components'] = self.n_groups\n",
    "\n",
    "        self.classifier_options = {\n",
    "            'solver': 'liblinear', 'C': 1.0, 'class_weight': 'balanced', 'random_state': random_state\n",
    "        }\n",
    "\n",
    "        if classifier_options:\n",
    "            self.classifier_options.update(classifier_options)\n",
    "            self.classifier_options['random_state'] = random_state\n",
    "\n",
    "        \n",
    "        self.gt_matrix_ = None\n",
    "        self.selected_column_sparsity_ = None\n",
    "        self.nmf_reconstruction_error_ = None\n",
    "        self.selection_hamming_loss_ = None\n",
    "        self.classifiers_ = None\n",
    "        self.train_time_ = None\n",
    "\n",
    "    def _reweight_proba_vector(self, P_initial, column_sparsity):\n",
    "        \"\"\"Reweights a probability vector.\"\"\"\n",
    "        n = len(P_initial)\n",
    "        Pi_weighted = column_sparsity * np.array(P_initial)\n",
    "        id1_mask = Pi_weighted >= 1\n",
    "\n",
    "        if np.sum(id1_mask) >= column_sparsity:\n",
    "            Pi_weighted[id1_mask] = 1\n",
    "            return Pi_weighted\n",
    "\n",
    "        id2_sorted_indices = np.argsort(Pi_weighted)[::-1]\n",
    "        tmp = Pi_weighted[id2_sorted_indices]\n",
    "\n",
    "        exc = 0.0\n",
    "        for j in range(n):\n",
    "            if tmp[j] >= 1.0:\n",
    "                exc += (tmp[j] - 1.0)\n",
    "                tmp[j] = 1.0\n",
    "            elif exc > 1e-9:\n",
    "                sum_remaining = np.sum(tmp[j:])\n",
    "                if sum_remaining > 1e-9:\n",
    "                    factor = 1.0 + exc / sum_remaining\n",
    "                    tmp[j:] *= factor\n",
    "                    exc = 0.0\n",
    "                else:\n",
    "                    remaining_count = n - j\n",
    "                    if remaining_count > 0:\n",
    "                        add_val = exc / remaining_count\n",
    "                        tmp[j:] += add_val\n",
    "                        exc = 0.0\n",
    "                became_one_mask = tmp[j:] >= 1.0\n",
    "                if np.any(became_one_mask):\n",
    "                    exc += np.sum(tmp[j:][became_one_mask] - 1.0)\n",
    "                    tmp[j:][became_one_mask] = 1.0\n",
    "\n",
    "            if np.sum(tmp >= 1.0) >= column_sparsity or exc < 1e-9:\n",
    "                Pi_final = np.zeros_like(Pi_weighted)\n",
    "                Pi_final[id2_sorted_indices] = tmp\n",
    "                Pi_final[Pi_final < 0] = 0\n",
    "                return Pi_final\n",
    "\n",
    "        Pi_final = np.zeros_like(Pi_weighted)\n",
    "        Pi_final[id2_sorted_indices] = tmp\n",
    "        Pi_final[Pi_final < 0] = 0\n",
    "        return Pi_final\n",
    "\n",
    "    def _build_sparse_rand_vector(self, P_initial, column_sparsity):\n",
    "        \"\"\"Generates a sparse random vector based on probabilities.\"\"\"\n",
    "        n = len(P_initial)\n",
    "        P_reweighted = self._reweight_proba_vector(P_initial, column_sparsity)\n",
    "        vec = np.zeros(n, dtype=np.int8)\n",
    "        rand_nums = np.random.rand(n)\n",
    "        vec[P_reweighted >= 1.0] = 1\n",
    "        sample_mask = (P_reweighted < 1.0) & (P_reweighted > 0)\n",
    "        vec[sample_mask] = (rand_nums[sample_mask] < P_reweighted[sample_mask]).astype(np.int8)\n",
    "        return csr_matrix(vec).T\n",
    "\n",
    "    def _build_gt_matrix(self, H_basis, column_sparsity):\n",
    "        \"\"\"Generates the full GT matrix A.\"\"\"\n",
    "        d, m = H_basis.shape # H_basis --> (d x m)\n",
    "        if m != self.n_groups:\n",
    "             print(f\"Warning: NMF basis dimension ({m}) differs from n_groups ({self.n_groups}). Using {m}.\")\n",
    "        A_cols = []\n",
    "        print(f\"Generating GT matrix A ({m} x {d}) with target column sparsity c={column_sparsity}...\")\n",
    "        for i in range(d):\n",
    "            H_row_i = H_basis[i, :]\n",
    "            sum_H_row_i = np.sum(H_row_i)\n",
    "            if sum_H_row_i > 1e-9:\n",
    "                P_initial = H_row_i / sum_H_row_i\n",
    "            else:\n",
    "                P_initial = np.ones(m) / m\n",
    "            A_col_i = self._build_sparse_rand_vector(P_initial, column_sparsity)\n",
    "            A_cols.append(A_col_i)\n",
    "\n",
    "            if (i + 1) % 50 == 0 or (i + 1) == d:\n",
    "                print(f\"Generated GT column {i+1}/{d}\")\n",
    "\n",
    "        A = hstack(A_cols, format='csc')\n",
    "        print(f\"Generated GT matrix A: shape {A.shape}, nnz {A.nnz}, avg col sparsity {A.nnz / d:.2f}\")\n",
    "        return A\n",
    "\n",
    "    def _build_A(self, Y_train_csc):\n",
    "        \"\"\"\n",
    "        Performs NMF, selects best 'c', and generates the GT matrix A.\n",
    "        Args:\n",
    "            Y_train_csc (csc_matrix): Training labels (d x n_train).\n",
    "        Returns:\n",
    "            tuple: (best_A, best_c, min_hamming_loss) or (None, None, None) if error.\n",
    "        \"\"\"\n",
    "        d, n_train = Y_train_csc.shape\n",
    "        print(f\"\\nSelecting best column sparsity 'c' from {self.column_sparsity_range}...\")\n",
    "        print(\"Calculating YYT (may take time)...\")\n",
    "\n",
    "        start_yyt = time.time()\n",
    "        try:\n",
    "            YYT = Y_train_csc @ Y_train_csc.T   # (d x d)\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating YYT: {e}.\")\n",
    "            return None, None, None\n",
    "        end_yyt = time.time()\n",
    "\n",
    "        print(f\"YYT calculation took {end_yyt - start_yyt:.2f}s. Shape: {YYT.shape}\")\n",
    "\n",
    "        if issparse(YYT):\n",
    "            neg_indices = YYT < 0\n",
    "            if neg_indices.nnz > 0:\n",
    "                print(f\"Warning: Found {neg_indices.nnz} negative values in sparse YYT. Clamping to 0.\")\n",
    "                YYT[neg_indices] = 0\n",
    "        else:\n",
    "            YYT[YYT < 0] = 0\n",
    "\n",
    "\n",
    "        print(f\"Performing NMF on YY^T (n_components={self.n_groups})...\")\n",
    "        start_nmf = time.time()\n",
    "        nmf_model = NMF(**self.nmf_options)\n",
    "        try:\n",
    "            H_basis = nmf_model.fit_transform(YYT)\n",
    "            self.nmf_reconstruction_error_ = nmf_model.reconstruction_err_\n",
    "\n",
    "        except TypeError:\n",
    "            print(\"NMF requires dense input, converting clamped YYT...\")\n",
    "            if YYT.nnz > 500e6:\n",
    "                print(\"Warning: YYT is very large\")\n",
    "            YYT_dense = YYT.toarray()\n",
    "            \n",
    "            H_basis = nmf_model.fit_transform(YYT_dense)\n",
    "            self.nmf_reconstruction_error_ = nmf_model.reconstruction_err_\n",
    "            del YYT_dense\n",
    "\n",
    "        except ValueError as ve:\n",
    "            if \"Negative values in data passed\" in str(ve):\n",
    "                print(\"Error: Negative values persist even after clamping. Check YYT calculation or NMF internal steps.\")\n",
    "            else:\n",
    "                print(f\"ValueError during NMF: {ve}\")\n",
    "            del YYT\n",
    "            return None, None, None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during NMF: {e}\")\n",
    "            del YYT\n",
    "            return None, None, None\n",
    "\n",
    "        end_nmf = time.time()\n",
    "        print(f\"NMF completed in {end_nmf - start_nmf:.2f}s. Basis shape: {H_basis.shape}, Rec. Error: {self.nmf_reconstruction_error_:.4f}\")\n",
    "        del YYT\n",
    "\n",
    "        \n",
    "        min_avg_hamming_loss = float('inf')\n",
    "        best_c = -1\n",
    "        generated_matrices = {}\n",
    "\n",
    "        n_eval = min(n_train, 500)\n",
    "        Y_eval_csc = Y_train_csc[:, :n_eval]\n",
    "\n",
    "        for c_val in self.column_sparsity_range:\n",
    "            # We calculate hamming loss\n",
    "            print(f\"\\n  Testing c = {c_val}...\")\n",
    "            A_candidate = self._build_gt_matrix(H_basis, c_val) # m x d\n",
    "            if A_candidate is None: \n",
    "                continue\n",
    "\n",
    "            # We evaluate Hamming Loss on subset Y_eval_csc (d x n_eval)\n",
    "            Z_reduced_eval = (A_candidate @ Y_eval_csc > 0).astype(np.int8) # m x n_eval\n",
    "            Scores_rec_eval = A_candidate.T @ Z_reduced_eval # d x n_eval\n",
    "\n",
    "            total_hamming_dist = 0\n",
    "            for l in range(n_eval):\n",
    "                scores_l = Scores_rec_eval[:, l].toarray().ravel()\n",
    "                y_true_l = Y_eval_csc[:, l].toarray().ravel()\n",
    "                k_actual = int(max(1, np.sum(y_true_l)))\n",
    "                k_predict = min(k_actual, self.k_target_sparsity)\n",
    "\n",
    "                if len(scores_l) == 0 or np.all(scores_l == scores_l[0]):\n",
    "                    top_k_indices = np.random.choice(d, size=min(k_predict, d), replace=False)\n",
    "                else:\n",
    "                    top_k_indices = np.argsort(scores_l)[::-1][:k_predict]\n",
    "\n",
    "                y_pred_l = np.zeros(d, dtype=np.int8)\n",
    "                if len(top_k_indices) > 0:\n",
    "                    y_pred_l[top_k_indices] = 1\n",
    "                total_hamming_dist += np.sum(y_pred_l != y_true_l)\n",
    "\n",
    "            avg_hamming_loss = total_hamming_dist / (n_eval * d)\n",
    "            generated_matrices[c_val] = A_candidate\n",
    "            print(f\"Avg Hamming Loss (on {n_eval} samples): {avg_hamming_loss:.6f}\")\n",
    "\n",
    "            if avg_hamming_loss < min_avg_hamming_loss:\n",
    "                min_avg_hamming_loss = avg_hamming_loss\n",
    "                best_c = c_val\n",
    "\n",
    "        if best_c == -1 and generated_matrices:\n",
    "            best_c = self.column_sparsity_range[0]\n",
    "            min_avg_hamming_loss = np.inf\n",
    "\n",
    "        print(f\"\\nSelected c = {best_c} with min Hamming Loss = {min_avg_hamming_loss:.6f}\")\n",
    "        best_A = generated_matrices.get(best_c)\n",
    "        if best_A is None:\n",
    "            print(\"Error: Could not retrieve the generated GT matrix for the best c\")\n",
    "            return None, None, None\n",
    "\n",
    "        self.selection_hamming_loss_ = min_avg_hamming_loss\n",
    "        return best_A, best_c, min_avg_hamming_loss\n",
    "\n",
    "    def _train_intermediate_classifiers(self, X_train, Y_reduced_train_csc):\n",
    "        \"\"\"Trains the m binary classifiers.\"\"\"\n",
    "        m = Y_reduced_train_csc.shape[0]\n",
    "        n_train = X_train.shape[0]\n",
    "        print(f\"\\nTraining {m} intermediate binary classifiers...\")\n",
    "        classifiers = []\n",
    "        num_skipped = 0\n",
    "        start_clf_time = time.time()\n",
    "\n",
    "        for j in range(m):\n",
    "            y_j = Y_reduced_train_csc[j, :].toarray().ravel()\n",
    "            unique_labels, counts = np.unique(y_j, return_counts=True)\n",
    "\n",
    "            if len(unique_labels) < 2:\n",
    "                num_skipped += 1\n",
    "                clf = ConstantPredictor(unique_labels[0])\n",
    "            else:\n",
    "                clf = LogisticRegression(**self.classifier_options)\n",
    "                try:\n",
    "                    clf.fit(X_train, y_j)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error training classifier {j}: {e}. Skipping.\")\n",
    "                    majority_class = unique_labels[np.argmax(counts)]\n",
    "                    clf = ConstantPredictor(majority_class)\n",
    "\n",
    "            classifiers.append(clf)\n",
    "            if (j + 1) % 1 == 0 or (j + 1) == m:\n",
    "                elapsed_time = time.time() - start_clf_time\n",
    "                print(f\"Trained classifier {j+1}/{m} ({elapsed_time:.1f}s elapsed)\")\n",
    "\n",
    "\n",
    "        print(f\"Skipped training for {num_skipped}/{m} classifiers due to constant labels.\")\n",
    "        print(f\"Classifier training finished in {time.time() - start_clf_time:.2f} seconds.\")\n",
    "        return classifiers\n",
    "\n",
    "\n",
    "    def fit(self, X_train, Y_train):\n",
    "        \"\"\"\n",
    "        Trains the NMF-GT model.\n",
    "        Args:\n",
    "            X_train (csr_matrix): Training features (n_samples x n_features).\n",
    "            Y_train (csr_matrix): Training labels (n_samples x d).\n",
    "        \"\"\"\n",
    "        print(\"\\n--- Starting NMF-GT Model Training ---\")\n",
    "        start_fit_time = time.time()\n",
    "        n_samples, n_features = X_train.shape\n",
    "        d = Y_train.shape[1]\n",
    "\n",
    "        if Y_train.shape[0] != n_samples:\n",
    "            raise ValueError(\"X_train and Y_train must have the same number of samples.\")\n",
    "\n",
    "        # Y_train is d x n_samples\n",
    "        Y_train_csc_T = Y_train.T.tocsc()\n",
    "        best_A, best_c, _ = self._build_A(Y_train_csc_T)\n",
    "        del Y_train_csc_T\n",
    "\n",
    "        if best_A is None:\n",
    "            print(\"Error: Failed to generate Group Testing matrix. Aborting fit.\")\n",
    "            self.train_time_ = time.time() - start_fit_time\n",
    "            return self\n",
    "\n",
    "        self.gt_matrix_ = best_A # m x d\n",
    "        self.selected_column_sparsity_ = best_c\n",
    "\n",
    "        print(\"\\nReducing training labels using the generated GT matrix...\")\n",
    "\n",
    "        # Y_reduced --> A @ Y.T --> m x n_samples\n",
    "        Y_train_T_csc = Y_train.T.tocsc()\n",
    "        Y_reduced_train = (self.gt_matrix_ @ Y_train_T_csc > 0).astype(np.int8)\n",
    "        Y_reduced_train_csc = Y_reduced_train.tocsc()\n",
    "\n",
    "        del Y_train_T_csc, Y_reduced_train\n",
    "        print(f\"Reduced training labels shape: {Y_reduced_train_csc.shape}\")\n",
    "\n",
    "        self.classifiers_ = self._train_intermediate_classifiers(X_train, Y_reduced_train_csc)\n",
    "\n",
    "        self.train_time_ = time.time() - start_fit_time\n",
    "        print(f\"NMF-GT Model Training Completed in {self.train_time_:.2f} seconds\")\n",
    "        return self\n",
    "\n",
    "    def predict_scores(self, X_test):\n",
    "        \"\"\"\n",
    "        Predicts the raw scores for new data samples.\n",
    "        Args:\n",
    "            X_test (csr_matrix): Test features (n_test_samples x n_features).\n",
    "        Returns:\n",
    "            csc_matrix: Predicted scores (d x n_test_samples), or None if not fitted.\n",
    "        \"\"\"\n",
    "        if self.gt_matrix_ is None or self.classifiers_ is None:\n",
    "            print(\"Error: Model has not been fitted yet. Call fit() first.\")\n",
    "            return None\n",
    "\n",
    "        print(\"\\n--- Predicting Scores ---\")\n",
    "        start_pred_time = time.time()\n",
    "        n_test_samples = X_test.shape[0]\n",
    "        m = self.n_groups\n",
    "\n",
    "        # We predict reduced labels\n",
    "        Z_pred_lil = lil_matrix((m, n_test_samples), dtype=np.int8)\n",
    "        print(f\"Predicting with {len(self.classifiers_)} intermediate classifiers...\")\n",
    "        for j, clf in enumerate(self.classifiers_):\n",
    "            if clf is None:\n",
    "                print(f\"Warning: Classifier {j} is missing. Predicting zeros for this group.\")\n",
    "                preds = np.zeros(n_test_samples, dtype=np.int8)\n",
    "            else:\n",
    "                try:\n",
    "                    preds = clf.predict(X_test)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error predicting with classifier {j}: {e}. Predicting zeros.\")\n",
    "                    preds = np.zeros(n_test_samples, dtype=np.int8)\n",
    "            Z_pred_lil[j, :] = preds\n",
    "\n",
    "        Z_pred_csr = Z_pred_lil.tocsr()\n",
    "        del Z_pred_lil\n",
    "\n",
    "        # We calculate final scores --> Scores = A.T @ Z_pred\n",
    "        A_csc = self.gt_matrix_.tocsc()\n",
    "        Scores_test = A_csc.T @ Z_pred_csr # d x n_test_samples\n",
    "        Scores_test_csc = Scores_test.tocsc()\n",
    "\n",
    "        end_pred_time = time.time()\n",
    "        print(f\"Score prediction finished in {end_pred_time - start_pred_time:.2f} seconds.\")\n",
    "        print(f\"Predicted scores shape: {Scores_test_csc.shape}\")\n",
    "        return Scores_test_csc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this class we implemented the precision@k and modified precision@k methods of evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \"\"\"Calculates evaluation metrics for multilabel classification.\"\"\"\n",
    "\n",
    "    def calculate_precision_at_k(self, scores, y_true, k_max):\n",
    "        \"\"\"\n",
    "        Calculates Precision@k for k = 1 to k_max.\n",
    "        Args:\n",
    "            scores (csc_matrix): Predicted scores (d x n_samples).\n",
    "            y_true (csr_matrix): True labels (n_samples x d).\n",
    "            k_max (int): Maximum k to calculate precision for.\n",
    "        Returns:\n",
    "            np.ndarray: Array of precision values for k=1 to k_max.\n",
    "        \"\"\"\n",
    "\n",
    "        if not issparse(scores) or not isinstance(scores, csc_matrix):\n",
    "            warnings.warn(\"Scores matrix is not CSC, converting.\")\n",
    "            scores = csc_matrix(scores)\n",
    "        if not issparse(y_true) or not isinstance(y_true, csr_matrix):\n",
    "            warnings.warn(\"True labels matrix is not CSR, converting.\")\n",
    "            y_true = csr_matrix(y_true)\n",
    "\n",
    "        n_samples = y_true.shape[0]\n",
    "        d = y_true.shape[1]\n",
    "\n",
    "        if scores.shape[0] != d or scores.shape[1] != n_samples:\n",
    "            raise ValueError(f\"Score matrix shape {scores.shape} incompatible with true label matrix shape {y_true.shape} (expected scores: {d}x{n_samples})\")\n",
    "\n",
    "        precisions = np.zeros(k_max)\n",
    "\n",
    "        print(f\"\\nCalculating Precision@k (up to k={k_max}) for {n_samples} test samples...\")\n",
    "        start_eval_time = time.time()\n",
    "\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            true_labels_i = y_true[i, :].toarray().ravel()\n",
    "            scores_i = scores[:, i].toarray().ravel()\n",
    "\n",
    "            actual_k_max = min(k_max, d)\n",
    "            if np.all(scores_i == scores_i[0]): \n",
    "                top_indices = np.random.choice(d, size=actual_k_max, replace=False)\n",
    "            else:\n",
    "                top_indices = np.argsort(scores_i)[::-1][:actual_k_max]\n",
    "\n",
    "            if len(top_indices) == 0: continue\n",
    "\n",
    "            hits_in_top_k = np.cumsum(true_labels_i[top_indices])\n",
    "\n",
    "            for k in range(1, actual_k_max + 1):\n",
    "                precisions[k - 1] += hits_in_top_k[k - 1] / k\n",
    "\n",
    "            if (i + 1) % 5000 == 0 or (i + 1) == n_samples:\n",
    "                elapsed = time.time() - start_eval_time\n",
    "                print(f\"  Processed {i+1}/{n_samples} samples for Precision@k... ({elapsed:.1f}s)\")\n",
    "\n",
    "        print(f\"Precision@k calculation finished in {time.time() - start_eval_time:.2f} seconds.\")\n",
    "        return precisions / n_samples\n",
    "\n",
    "    def modified_precision_at_k(self, scores, y_true, k_max, k_pred_fixed=5):\n",
    "        \"\"\"\n",
    "        Calculates the modified Precision@k (II@k)\n",
    "        Args:\n",
    "            scores (csc_matrix): Predicted scores (d x n_samples).\n",
    "            y_true (csr_matrix): True labels (n_samples x d).\n",
    "            k_max (int): Maximum evaluation k\n",
    "            k_pred_fixed (int): The fixed number of top scoring labels used to define y_hat\n",
    "        Returns:\n",
    "            np.ndarray: Array of II@k values for k=1 to k_max.\n",
    "        \"\"\"\n",
    "\n",
    "        if not issparse(scores) or not isinstance(scores, csc_matrix):\n",
    "            warnings.warn(\"Scores matrix is not CSC, converting.\")\n",
    "            scores = csc_matrix(scores)\n",
    "        if not issparse(y_true) or not isinstance(y_true, csr_matrix):\n",
    "            warnings.warn(\"True labels matrix is not CSR, converting.\")\n",
    "            y_true = csr_matrix(y_true)\n",
    "\n",
    "        n_samples = y_true.shape[0]\n",
    "        d = y_true.shape[1]\n",
    "\n",
    "        if scores.shape[0] != d or scores.shape[1] != n_samples:\n",
    "            raise ValueError(f\"Score matrix shape {scores.shape} incompatible with true label matrix shape {y_true.shape} (expected scores: {d}x{n_samples})\")\n",
    "\n",
    "        actual_k_pred = min(k_pred_fixed, d)\n",
    "        if actual_k_pred != k_pred_fixed:\n",
    "            print(f\"Warning: k_pred_fixed ({k_pred_fixed}) > number of labels ({d}). Using {d}.\")\n",
    "\n",
    "        pi_values = np.zeros(k_max) \n",
    "\n",
    "        print(f\"\\nCalculating Modified Precision II@k (up to k={k_max}, using top {actual_k_pred} scores for ŷ) for {n_samples} test samples...\")\n",
    "        start_eval_time = time.time()\n",
    "\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            \n",
    "            true_labels_i = y_true[i, :].toarray().ravel() \n",
    "            scores_i = scores[:, i].toarray().ravel()     \n",
    "\n",
    "            if np.all(scores_i == scores_i[0]):\n",
    "                top_k_pred_indices = np.random.choice(d, size=actual_k_pred, replace=False)\n",
    "            else:\n",
    "                top_k_pred_indices = np.argsort(scores_i)[::-1][:actual_k_pred]\n",
    "\n",
    "            if len(top_k_pred_indices) == 0: \n",
    "                continue\n",
    "\n",
    "            total_hits_in_top_k_pred = np.sum(true_labels_i[top_k_pred_indices])\n",
    "\n",
    "            for k_eval_loop in range(1, k_max + 1):\n",
    "                pi_k = (1 / k_eval_loop) * min(k_eval_loop, total_hits_in_top_k_pred)\n",
    "                pi_values[k_eval_loop - 1] += pi_k\n",
    "\n",
    "            if (i + 1) % 5000 == 0 or (i + 1) == n_samples:\n",
    "                elapsed = time.time() - start_eval_time\n",
    "                print(f\"  Processed {i+1}/{n_samples} samples for Π@k... ({elapsed:.1f}s)\")\n",
    "\n",
    "        print(f\"II@k calculation finished in {time.time() - start_eval_time:.2f} seconds.\")\n",
    "\n",
    "        return pi_values / n_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file paths\n",
    "data_filepath = 'Bibtex/Bibtex_data.txt'\n",
    "train_split_filepath = 'Bibtex/bibtex_trSplit.txt'\n",
    "test_split_filepath = 'Bibtex/bibtex_tstSplit.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters for the NMFGT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "n_groups_m = 120\n",
    "k_target = 5\n",
    "c_range = list(range(10, 71, 10))\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling DataLoader to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading full dataset from Bibtex/Bibtex_data.txt...\n",
      "Loaded data: X shape (7395, 1836), Y shape (7395, 159)\n",
      "X sparsity: 0.0374\n",
      "Y sparsity: 0.0151\n",
      "Loading train split from Bibtex/bibtex_trSplit.txt...\n",
      "Loading test split from Bibtex/bibtex_tstSplit.txt...\n",
      "\n",
      "Splitting data...\n",
      "Train shapes: X=(48800, 1836), Y=(48800, 159)\n",
      "Test shapes:  X=(25150, 1836), Y=(25150, 159)\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader()\n",
    "X_train, Y_train, X_test, Y_test = data_loader.get_train_test_split(\n",
    "    data_filepath, train_split_filepath, test_split_filepath\n",
    ")\n",
    "\n",
    "if X_train is None:\n",
    "    raise(f\"Loading was unsuccessful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfgt_model = NMFGTModel(\n",
    "    n_groups=n_groups_m,\n",
    "    k_target_sparsity=k_target,\n",
    "    column_sparsity_range=c_range,\n",
    "    random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the NMFGT model for the loaded dataset and the provided hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48800, 1836)\n",
      "(48800, 159)\n",
      "\n",
      "--- Starting NMF-GT Model Training ---\n",
      "\n",
      "Selecting best column sparsity 'c' from [10, 20, 30, 40, 50, 60, 70]...\n",
      "Calculating YYT (may take time)...\n",
      "YYT calculation took 0.02s. Shape: (159, 159)\n",
      "Warning: Found 393 negative values in sparse YYT. Clamping to 0.\n",
      "Performing NMF on YY^T (n_components=120)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF completed in 1.41s. Basis shape: (159, 120), Rec. Error: 494.6756\n",
      "\n",
      "  Testing c = 10...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=10...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 1592, avg col sparsity 10.01\n",
      "Avg Hamming Loss (on 500 samples): 0.003044\n",
      "\n",
      "  Testing c = 20...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=20...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 3171, avg col sparsity 19.94\n",
      "Avg Hamming Loss (on 500 samples): 0.002465\n",
      "\n",
      "  Testing c = 30...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=30...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 4825, avg col sparsity 30.35\n",
      "Avg Hamming Loss (on 500 samples): 0.004654\n",
      "\n",
      "  Testing c = 40...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=40...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 6342, avg col sparsity 39.89\n",
      "Avg Hamming Loss (on 500 samples): 0.009258\n",
      "\n",
      "  Testing c = 50...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=50...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 8075, avg col sparsity 50.79\n",
      "Avg Hamming Loss (on 500 samples): 0.013711\n",
      "\n",
      "  Testing c = 60...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=60...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 9456, avg col sparsity 59.47\n",
      "Avg Hamming Loss (on 500 samples): 0.017560\n",
      "\n",
      "  Testing c = 70...\n",
      "Generating GT matrix A (120 x 159) with target column sparsity c=70...\n",
      "Generated GT column 50/159\n",
      "Generated GT column 100/159\n",
      "Generated GT column 150/159\n",
      "Generated GT column 159/159\n",
      "Generated GT matrix A: shape (120, 159), nnz 11183, avg col sparsity 70.33\n",
      "Avg Hamming Loss (on 500 samples): 0.020503\n",
      "\n",
      "Selected c = 20 with min Hamming Loss = 0.002465\n",
      "\n",
      "Reducing training labels using the generated GT matrix...\n",
      "Reduced training labels shape: (120, 48800)\n",
      "\n",
      "Training 120 intermediate binary classifiers...\n",
      "Trained classifier 1/120 (5.8s elapsed)\n",
      "Trained classifier 2/120 (10.9s elapsed)\n",
      "Trained classifier 3/120 (18.2s elapsed)\n",
      "Trained classifier 4/120 (22.4s elapsed)\n",
      "Trained classifier 5/120 (27.9s elapsed)\n",
      "Trained classifier 6/120 (33.2s elapsed)\n",
      "Trained classifier 7/120 (40.0s elapsed)\n",
      "Trained classifier 8/120 (45.8s elapsed)\n",
      "Trained classifier 9/120 (51.1s elapsed)\n",
      "Trained classifier 10/120 (54.5s elapsed)\n",
      "Trained classifier 11/120 (60.9s elapsed)\n",
      "Trained classifier 12/120 (70.0s elapsed)\n",
      "Trained classifier 13/120 (75.7s elapsed)\n",
      "Trained classifier 14/120 (81.0s elapsed)\n",
      "Trained classifier 15/120 (87.1s elapsed)\n",
      "Trained classifier 16/120 (92.7s elapsed)\n",
      "Trained classifier 17/120 (97.1s elapsed)\n",
      "Trained classifier 18/120 (105.6s elapsed)\n",
      "Trained classifier 19/120 (112.9s elapsed)\n",
      "Trained classifier 20/120 (122.9s elapsed)\n",
      "Trained classifier 21/120 (129.4s elapsed)\n",
      "Trained classifier 22/120 (136.5s elapsed)\n",
      "Trained classifier 23/120 (142.5s elapsed)\n",
      "Trained classifier 24/120 (149.4s elapsed)\n",
      "Trained classifier 25/120 (154.3s elapsed)\n",
      "Trained classifier 26/120 (160.0s elapsed)\n",
      "Trained classifier 27/120 (166.1s elapsed)\n",
      "Trained classifier 28/120 (171.0s elapsed)\n",
      "Trained classifier 29/120 (174.5s elapsed)\n",
      "Trained classifier 30/120 (180.1s elapsed)\n",
      "Trained classifier 31/120 (186.0s elapsed)\n",
      "Trained classifier 32/120 (191.6s elapsed)\n",
      "Trained classifier 33/120 (196.9s elapsed)\n",
      "Trained classifier 34/120 (203.6s elapsed)\n",
      "Trained classifier 35/120 (208.0s elapsed)\n",
      "Trained classifier 36/120 (214.6s elapsed)\n",
      "Trained classifier 37/120 (221.7s elapsed)\n",
      "Trained classifier 38/120 (227.4s elapsed)\n",
      "Trained classifier 39/120 (232.6s elapsed)\n",
      "Trained classifier 40/120 (238.3s elapsed)\n",
      "Trained classifier 41/120 (246.3s elapsed)\n",
      "Trained classifier 42/120 (250.5s elapsed)\n",
      "Trained classifier 43/120 (256.6s elapsed)\n",
      "Trained classifier 44/120 (262.2s elapsed)\n",
      "Trained classifier 45/120 (267.5s elapsed)\n",
      "Trained classifier 46/120 (271.4s elapsed)\n",
      "Trained classifier 47/120 (276.9s elapsed)\n",
      "Trained classifier 48/120 (281.7s elapsed)\n",
      "Trained classifier 49/120 (287.5s elapsed)\n",
      "Trained classifier 50/120 (293.9s elapsed)\n",
      "Trained classifier 51/120 (298.5s elapsed)\n",
      "Trained classifier 52/120 (304.8s elapsed)\n",
      "Trained classifier 53/120 (309.9s elapsed)\n",
      "Trained classifier 54/120 (315.4s elapsed)\n",
      "Trained classifier 55/120 (321.1s elapsed)\n",
      "Trained classifier 56/120 (325.7s elapsed)\n",
      "Trained classifier 57/120 (330.5s elapsed)\n",
      "Trained classifier 58/120 (336.8s elapsed)\n",
      "Trained classifier 59/120 (341.6s elapsed)\n",
      "Trained classifier 60/120 (346.8s elapsed)\n",
      "Trained classifier 61/120 (352.7s elapsed)\n",
      "Trained classifier 62/120 (358.0s elapsed)\n",
      "Trained classifier 63/120 (362.6s elapsed)\n",
      "Trained classifier 64/120 (367.1s elapsed)\n",
      "Trained classifier 65/120 (373.0s elapsed)\n",
      "Trained classifier 66/120 (379.5s elapsed)\n",
      "Trained classifier 67/120 (384.7s elapsed)\n",
      "Trained classifier 68/120 (390.3s elapsed)\n",
      "Trained classifier 69/120 (395.0s elapsed)\n",
      "Trained classifier 70/120 (400.3s elapsed)\n",
      "Trained classifier 71/120 (405.3s elapsed)\n",
      "Trained classifier 72/120 (410.7s elapsed)\n",
      "Trained classifier 73/120 (416.0s elapsed)\n",
      "Trained classifier 74/120 (420.9s elapsed)\n",
      "Trained classifier 75/120 (425.2s elapsed)\n",
      "Trained classifier 76/120 (431.2s elapsed)\n",
      "Trained classifier 77/120 (435.1s elapsed)\n",
      "Trained classifier 78/120 (440.0s elapsed)\n",
      "Trained classifier 79/120 (445.3s elapsed)\n",
      "Trained classifier 80/120 (450.9s elapsed)\n",
      "Trained classifier 81/120 (456.1s elapsed)\n",
      "Trained classifier 82/120 (461.2s elapsed)\n",
      "Trained classifier 83/120 (465.4s elapsed)\n",
      "Trained classifier 84/120 (470.0s elapsed)\n",
      "Trained classifier 85/120 (475.8s elapsed)\n",
      "Trained classifier 86/120 (481.6s elapsed)\n",
      "Trained classifier 87/120 (487.3s elapsed)\n",
      "Trained classifier 88/120 (491.8s elapsed)\n",
      "Trained classifier 89/120 (497.0s elapsed)\n",
      "Trained classifier 90/120 (502.5s elapsed)\n",
      "Trained classifier 91/120 (507.6s elapsed)\n",
      "Trained classifier 92/120 (511.8s elapsed)\n",
      "Trained classifier 93/120 (518.1s elapsed)\n",
      "Trained classifier 94/120 (523.7s elapsed)\n",
      "Trained classifier 95/120 (529.6s elapsed)\n",
      "Trained classifier 96/120 (534.2s elapsed)\n",
      "Trained classifier 97/120 (540.0s elapsed)\n",
      "Trained classifier 98/120 (546.3s elapsed)\n",
      "Trained classifier 99/120 (551.2s elapsed)\n",
      "Trained classifier 100/120 (556.3s elapsed)\n",
      "Trained classifier 101/120 (560.8s elapsed)\n",
      "Trained classifier 102/120 (564.9s elapsed)\n",
      "Trained classifier 103/120 (571.0s elapsed)\n",
      "Trained classifier 104/120 (575.5s elapsed)\n",
      "Trained classifier 105/120 (580.5s elapsed)\n",
      "Trained classifier 106/120 (585.7s elapsed)\n",
      "Trained classifier 107/120 (592.4s elapsed)\n",
      "Trained classifier 108/120 (597.1s elapsed)\n",
      "Trained classifier 109/120 (601.5s elapsed)\n",
      "Trained classifier 110/120 (605.6s elapsed)\n",
      "Trained classifier 111/120 (610.8s elapsed)\n",
      "Trained classifier 112/120 (617.2s elapsed)\n",
      "Trained classifier 113/120 (622.7s elapsed)\n",
      "Trained classifier 114/120 (627.6s elapsed)\n",
      "Trained classifier 115/120 (632.5s elapsed)\n",
      "Trained classifier 116/120 (636.8s elapsed)\n",
      "Trained classifier 117/120 (641.3s elapsed)\n",
      "Trained classifier 118/120 (647.0s elapsed)\n",
      "Trained classifier 119/120 (652.0s elapsed)\n",
      "Trained classifier 120/120 (656.6s elapsed)\n",
      "Skipped training for 0/120 classifiers due to constant labels.\n",
      "Classifier training finished in 656.62 seconds.\n",
      "NMF-GT Model Training Completed in 660.81 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.NMFGTModel at 0x1b0190786e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "nmfgt_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the test by recreating the y data and creating the test_scores matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Predicting Scores ---\n",
      "Predicting with 120 intermediate classifiers...\n",
      "Score prediction finished in 1.70 seconds.\n",
      "Predicted scores shape: (159, 25150)\n"
     ]
    }
   ],
   "source": [
    "# We predict scores\n",
    "test_scores = nmfgt_model.predict_scores(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation using p@k anf pi@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating Precision@k (up to k=5) for 25150 test samples...\n",
      "  Processed 5000/25150 samples for Precision@k... (2.3s)\n",
      "  Processed 10000/25150 samples for Precision@k... (4.3s)\n",
      "  Processed 15000/25150 samples for Precision@k... (6.3s)\n",
      "  Processed 20000/25150 samples for Precision@k... (8.4s)\n",
      "  Processed 25000/25150 samples for Precision@k... (10.3s)\n",
      "  Processed 25150/25150 samples for Precision@k... (10.4s)\n",
      "Precision@k calculation finished in 10.41 seconds.\n",
      "\n",
      "Calculating Modified Precision II@k (up to k=5, using top 5 scores for ŷ) for 25150 test samples...\n",
      "  Processed 5000/25150 samples for Π@k... (2.1s)\n",
      "  Processed 10000/25150 samples for Π@k... (4.2s)\n",
      "  Processed 15000/25150 samples for Π@k... (6.3s)\n",
      "  Processed 20000/25150 samples for Π@k... (8.4s)\n",
      "  Processed 25000/25150 samples for Π@k... (10.5s)\n",
      "  Processed 25150/25150 samples for Π@k... (10.5s)\n",
      "II@k calculation finished in 10.53 seconds.\n",
      "\n",
      "--- Final NMF-GT Results (Bibtex) ---\n",
      "Parameters: n_groups(m)=120, k_target=5\n",
      "Selected Column Sparsity (c): 20\n",
      "NMF Reconstruction Error: 494.6756\n",
      "Min Hamming Loss during c selection: 0.002465\n",
      "Total Training Time: 660.81 seconds\n",
      "\n",
      "Precision@k (on test set):\n",
      " P@1: 0.9083\n",
      " P@2: 0.7064\n",
      " P@3: 0.5555\n",
      " P@4: 0.4516\n",
      " P@5: 0.3790\n",
      "\n",
      "Modified Precision II@k (on test set):\n",
      " II@1: 0.9821\n",
      " II@2: 0.7729\n",
      " II@3: 0.6052\n",
      " II@4: 0.4721\n",
      " II@5: 0.3790\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "if test_scores is not None:\n",
    "    evaluator = Evaluator()\n",
    "    precision_results = evaluator.calculate_precision_at_k(test_scores, Y_test, k_max=k_target)\n",
    "    pi_results = evaluator.modified_precision_at_k(test_scores, Y_test, k_max=k_target)\n",
    "\n",
    "    print(\"\\n--- Final NMF-GT Results (Bibtex) ---\")\n",
    "    print(f\"Parameters: n_groups(m)={nmfgt_model.n_groups}, k_target={nmfgt_model.k_target_sparsity}\")\n",
    "    print(f\"Selected Column Sparsity (c): {nmfgt_model.selected_column_sparsity_}\")\n",
    "    print(f\"NMF Reconstruction Error: {nmfgt_model.nmf_reconstruction_error_:.4f}\")\n",
    "    print(f\"Min Hamming Loss during c selection: {nmfgt_model.selection_hamming_loss_:.6f}\")\n",
    "    print(f\"Total Training Time: {nmfgt_model.train_time_:.2f} seconds\")\n",
    "\n",
    "    print(\"\\nPrecision@k (on test set):\")\n",
    "    max_k_report = min(k_target, len(precision_results))\n",
    "    for k_idx in range(max_k_report):\n",
    "        print(f\" P@{k_idx+1}: {precision_results[k_idx]:.4f}\")\n",
    "\n",
    "    print(\"\\nModified Precision II@k (on test set):\")\n",
    "    max_k_report = min(k_target, len(pi_results))\n",
    "    for k_idx in range(max_k_report):\n",
    "        print(f\" II@{k_idx+1}: {pi_results[k_idx]:.4f}\")\n",
    "else:\n",
    "    print(\"\\nScore prediction failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90831014, 0.70636183, 0.55554672, 0.45161034, 0.37904573])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98214712, 0.77294235, 0.60516899, 0.47213718, 0.37904573])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ks = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ks, precision_results, 'r*-', label='Precision')\n",
    "plt.plot(ks, pi_results, 'g*-', label='Precision_modified')\n",
    "\n",
    "plt.title('Precision RCV1x Test data')\n",
    "plt.ylabel('Precision@k')\n",
    "plt.xlabel('k')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
